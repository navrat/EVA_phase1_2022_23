{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navrat/EVA_phase1_2022_23/blob/main/2solutions_of_EVA4_Session_2_NaveenR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch # torch is a library to perform numerical computations. Torch provides a wide range of functions for working with arrays, including mathematical operations, linear algebra, and random number generation. It also has many features specifically designed for working with neural networks, such as tools for defining and training models, and algorithms for optimization and regularization \n",
        "import torch.nn as nn # torch.nn provides different classes within that make up the individidual components of a neural network like layers, containers. every module in torch subclasses the nn module\n",
        "import torch.nn.functional as F # Module that contains a host of stateless functions to create neural networks. One of the main advantages of using torch.nn.functional is that it allows users to easily define and apply custom functions to their data, without having to create and train a full neural network model\n",
        "import torch.optim as optim # torch.optim is a PyTorch package containing various optimization algorithms. Most commonly used methods for optimizers are already supported and custom optimizers can be built into it as well.\n",
        "from torchvision import datasets, transforms # The TorchVision datasets subpackage is a convenient utility for accessing well-known public image and video datasets. It contains methods like __getitem__ and __len__ since this module and its datasets are subclasses of torch.utils.data.Datasets. Transforms are common image transformations. They can be chained together using Compose. Additionally, there is the torchvision.transforms.functional module. Functional transforms give fine-grained control over the transformations. This is useful if you have to build a more complex transformation pipeline (like for segmentation tasks).\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "# Two ways to build this:\n",
        "# 1. use a final conv layer (conv7) without a relu activation\n",
        "# 2. use a fully connected layer after conv 7 by flattening it first\n",
        "class Net(nn.Module): # defines the class Net by inheriting from nn.Module \n",
        "    def __init__(self): # Constructors are used to initializing the object’s state. The task of constructors is to initialize(assign values) to the data members of the class when an object of the class is created. Like methods, a constructor also contains a collection of statements(i.e. instructions) that are executed at the time of Object creation. It is run as soon as an object of a class is instantiated. The method is useful to do any initialization you want to do with your object. Keyword self represents the instance of a class and binds the attributes with the given arguments\n",
        "        super(Net, self).__init__() # In an inherited subclass, a parent class can be referred with the use of the super() function. The super function returns a temporary object of the superclass that allows access to all of its methods to its child class.\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1) # convolution layer with 32 of 3*3 kernels. 1*28*28 (1*30*30 with padding) - 32*28*28 - RF = 3*3\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # convolution layer with 64 of 3*3 kernels.  32*28*28 (1*30*30 with padding) - 64*28*28 - RF = 5*5\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # max pooling using a 2*2 kernel. 64*28*28 - 64*14*14 - RF = 10*10\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) # convolution layer with 128 of 3*3 kernels.  64*14*14 (64*16*16 with padding) - 128*14*14 - RF = 12*12\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) # convolution layer with 256 of 3*3 kernels.  128*14*14 (128*16*16 with padding) - 256*14*14 - RF = 14*14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # max pooling using a 2*2 kernel. 256*14*14 - 256*7*7 - RF = 28*28\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)# convolution layer with 512 of 3*3 kernels.  256*7*7 - 512*5*5 - RF = 30*30 (larger than image size?)\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)# convolution layer with 1024 of 3*3 kernels.  512*5*5 - 1024*3*3 - RF = 32*32 (larger than image size?)\n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)# convolution layer with 10 of 3*3 kernels.  1024*3*3 - 10*1*1 - RF = 34*34 (larger than image size?)\n",
        "        # self.lin = nn.Linear(10,10) # option 2 - flattening \n",
        "\n",
        "    def forward(self, x): # module to implement the sequential neural network\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))) # sequence of conv1 taking input imagge and output activated by rely, passes to conv2 activated by relu and pooled. \n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))) # sequence of taking above output and passing to conv3 and output activated by rely, passes to conv4 activated by relu and pooled. \n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x)))) # sequence of taking above output and passing to conv5 and output activated by relu. passes to conv6 and activated by relu.\n",
        "        x = self.conv7(x)# sequence of taking above output and passing to conv7 and output activated by relu\n",
        "        x = x.view(-1, 10) # flattening the output to 1-d (original)\n",
        "        # x = F.relu(self.conv7(x)) # option 2 - sequence of taking above output and passing to conv7 and output activated by relu\n",
        "        # x = self.lin(x.view(-1, 10)) # option 2 - flattening the output to 1-d (original vs. addition of lin)\n",
        "        return F.log_softmax(x) # return the logged softmax of the 1-d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d9fe44-c6b0-4b4d-e1e7-f9e1c5228b81"
      },
      "source": [
        "# !pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-6dd4e6389635>:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) # return the logged softmax of the 1-d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1) # setting seed for reproducibility oninitializations and optimizer tasks\n",
        "batch_size = 128 # number of images used in each batch to train the network\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True, # loading the mnist train dataset\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs) # shuffling randomly selected images in each train batch\n",
        "test_loader = torch.utils.data.DataLoader( # loading the mnist test dataset\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs) # shuffling randomly selected images in each test batch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb112f7-ec5e-4160-b429-e6d7e1980307"
      },
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # learning rate and momentum based stochastic gradient descent\n",
        "\n",
        "for epoch in range(1, 2): # model trained for 1 epochs (1 pass of full data)\n",
        "    train(model, device, train_loader, optimizer, epoch) # trained on train data with model defined before\n",
        "    test(model, device, test_loader) # scored on test for accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-13-6dd4e6389635>:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x) # return the logged softmax of the 1-d\n",
            "loss=0.08471661061048508 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 26.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0668, Accuracy: 9774/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# controlled for batch size\n",
        "\n",
        "batch - loss - accuracy\n",
        "\n",
        "128 - 1.9 - 28%\n",
        "\n",
        "64 - 1.866 - 29% \n",
        "\n",
        "32 - 1.8658  - 29% \n",
        "\n",
        "16 - 1.454 - 48%"
      ],
      "metadata": {
        "id": "UFXDU7ts0nVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "controlled for learning rate\n",
        "\n",
        "at 0.001\n",
        "\n",
        "batch - loss - accuracy\n",
        "\n",
        "128 - 2.17 - 19%\n",
        "\n",
        "32 - 1.8995 - 28%\n",
        "\n",
        "16 - 1.27 - 48%"
      ],
      "metadata": {
        "id": "WXD3AuUx2oJC"
      }
    }
  ]
}