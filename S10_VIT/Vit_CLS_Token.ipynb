{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhgPeprM9fw/Bb0fWsYnuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ec5710b7bbf4703aacb8dd97d20efd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1734a1ec9c44469b74e0385f7401776",
              "IPY_MODEL_2c706e8becf5448787b34bb4116b3186",
              "IPY_MODEL_755207e94faf4e4d8796a746cfca4068"
            ],
            "layout": "IPY_MODEL_b696f2ac61b64805bcb5dc8ac0b4dc3b"
          }
        },
        "d1734a1ec9c44469b74e0385f7401776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a51d2e19b7a44e9389d0b20d891a3e1f",
            "placeholder": "​",
            "style": "IPY_MODEL_c95c51c0ca474dc0aefe5aa70254d993",
            "value": "100%"
          }
        },
        "2c706e8becf5448787b34bb4116b3186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88dfaf8d9eb64da99157ea25b6c47d34",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3cff34a21904817a2f29008949c8bc1",
            "value": 170498071
          }
        },
        "755207e94faf4e4d8796a746cfca4068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab40b6e339c4642960af9c483293b93",
            "placeholder": "​",
            "style": "IPY_MODEL_a2c2a02cbcd745a591ea19417ce9bb58",
            "value": " 170498071/170498071 [00:05&lt;00:00, 34282461.91it/s]"
          }
        },
        "b696f2ac61b64805bcb5dc8ac0b4dc3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51d2e19b7a44e9389d0b20d891a3e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c95c51c0ca474dc0aefe5aa70254d993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88dfaf8d9eb64da99157ea25b6c47d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3cff34a21904817a2f29008949c8bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eab40b6e339c4642960af9c483293b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c2a02cbcd745a591ea19417ce9bb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navrat/EVA_phase1_2022_23/blob/main/S10_VIT/Vit_CLS_Token.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "RXhABfirbaAj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './data/'"
      ],
      "metadata": {
        "id": "uth7w6l7iESJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "484kuc9tiG94",
        "outputId": "6b176a3a-0f72-4391-ece9-5df46e796fcd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, *layers):\n",
        "        super().__init__()\n",
        "        self.residual = nn.Sequential(*layers)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x + self.gamma * self.residual(x)"
      ],
      "metadata": {
        "id": "t4qw1XFeiR0C"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormChannels(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(channels)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, -1)\n",
        "        x = self.norm(x)\n",
        "        x = x.transpose(-1, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "c61UN8C3ixhB"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, head_channels, shape):\n",
        "        super().__init__()\n",
        "        self.heads = out_channels // head_channels\n",
        "        self.head_channels = head_channels\n",
        "        self.scale = head_channels**-0.5\n",
        "        \n",
        "        self.to_keys = nn.Conv2d(in_channels, out_channels, 1)\n",
        "        self.to_queries = nn.Conv2d(in_channels, out_channels, 1)\n",
        "        self.to_values = nn.Conv2d(in_channels, out_channels, 1)\n",
        "        self.unifyheads = nn.Conv2d(out_channels, out_channels, 1)\n",
        "        \n",
        "        height, width = shape\n",
        "        self.pos_enc = nn.Parameter(torch.Tensor(self.heads, (2 * height - 1) * (2 * width - 1)))\n",
        "        self.register_buffer(\"relative_indices\", self.get_indices(height, width))\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, out_channels))\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        b, _, h, w = x.shape\n",
        "        \n",
        "        keys = self.to_keys(x).view(b, self.heads, self.head_channels, -1)\n",
        "        values = self.to_values(x).view(b, self.heads, self.head_channels, -1)\n",
        "        queries = self.to_queries(x).view(b, self.heads, self.head_channels, -1)\n",
        "        \n",
        "        att = keys.transpose(-2, -1) @ queries\n",
        "        \n",
        "        indices = self.relative_indices.expand(self.heads, -1)\n",
        "        \n",
        "        rel_pos_enc = self.pos_enc.gather(-1, indices)\n",
        "        rel_pos_enc = rel_pos_enc.unflatten(-1, (h * w, h * w))\n",
        "        \n",
        "        att = att * self.scale + rel_pos_enc\n",
        "        att = F.softmax(att, dim=-2)\n",
        "        \n",
        "        out = values @ att\n",
        "        out = out.view(b, -1, h, w)\n",
        "        out = self.unifyheads(out)\n",
        "        return out\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_indices(h, w):\n",
        "        y = torch.arange(h, dtype=torch.long)\n",
        "        x = torch.arange(w, dtype=torch.long)\n",
        "        \n",
        "        y1, x1, y2, x2 = torch.meshgrid(y, x, y, x, indexing='ij')\n",
        "        indices = (y1 - y2 + h - 1) * (2 * w - 1) + x1 - x2 + w - 1\n",
        "        indices = indices.flatten()\n",
        "        \n",
        "        return indices"
      ],
      "metadata": {
        "id": "m8EmZjRUlcau"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Tensor(2,(2*2-1),(2*2-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47PozEHklcdI",
        "outputId": "84dec655-b241-4f70-bb1a-8412983763ea"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2.1707e-18, 7.0952e+22, 1.7748e+28],\n",
              "         [1.8176e+31, 7.2708e+31, 5.0778e+31],\n",
              "         [3.2608e-12, 1.7728e+28, 7.0367e+22]],\n",
              "\n",
              "        [[2.1715e-18, 1.0871e-05, 2.6217e+20],\n",
              "         [2.1574e-04, 3.3237e+21, 1.6535e-04],\n",
              "         [1.3086e-11, 2.1123e+20, 4.2886e-08]]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1,2],[3,4]])\n",
        "torch.gather(t,1, torch.tensor([[0,0],[1,0]])) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqu7Z0JRlcft",
        "outputId": "73d31bdd-6393-4840-d318-6138ea73456a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1],\n",
              "        [4, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.arange(4, dtype = torch.long)\n",
        "x = torch.arange(4, dtype = torch.long)\n",
        "print(y)\n",
        "print(x)\n",
        "torch.meshgrid(y, x, indexing='ij')\n",
        "# Basically each axis is replicated as many times as the dimension of the other axis to produce the full gridspace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j36QI0Q8vbD",
        "outputId": "a2b388cc-7cda-442e-ce29-42ebbb2c5ebb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([0, 1, 2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0, 0, 0, 0],\n",
              "         [1, 1, 1, 1],\n",
              "         [2, 2, 2, 2],\n",
              "         [3, 3, 3, 3]]), tensor([[0, 1, 2, 3],\n",
              "         [0, 1, 2, 3],\n",
              "         [0, 1, 2, 3],\n",
              "         [0, 1, 2, 3]]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.arange(4, dtype = torch.long)\n",
        "x = torch.arange(4, dtype = torch.long)\n",
        "print(y)\n",
        "print(x)\n",
        "torch.meshgrid(y, x, y, indexing='ij')\n",
        "# Basically each axis is replicated as many times as the dimension of the other axis to produce the full gridspace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anf3gIkO9yZw",
        "outputId": "75537f9c-85a8-4c7c-8063-34402eb26802"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([0, 1, 2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0, 0, 0, 0],\n",
              "          [0, 0, 0, 0],\n",
              "          [0, 0, 0, 0],\n",
              "          [0, 0, 0, 0]],\n",
              " \n",
              "         [[1, 1, 1, 1],\n",
              "          [1, 1, 1, 1],\n",
              "          [1, 1, 1, 1],\n",
              "          [1, 1, 1, 1]],\n",
              " \n",
              "         [[2, 2, 2, 2],\n",
              "          [2, 2, 2, 2],\n",
              "          [2, 2, 2, 2],\n",
              "          [2, 2, 2, 2]],\n",
              " \n",
              "         [[3, 3, 3, 3],\n",
              "          [3, 3, 3, 3],\n",
              "          [3, 3, 3, 3],\n",
              "          [3, 3, 3, 3]]]), tensor([[[0, 0, 0, 0],\n",
              "          [1, 1, 1, 1],\n",
              "          [2, 2, 2, 2],\n",
              "          [3, 3, 3, 3]],\n",
              " \n",
              "         [[0, 0, 0, 0],\n",
              "          [1, 1, 1, 1],\n",
              "          [2, 2, 2, 2],\n",
              "          [3, 3, 3, 3]],\n",
              " \n",
              "         [[0, 0, 0, 0],\n",
              "          [1, 1, 1, 1],\n",
              "          [2, 2, 2, 2],\n",
              "          [3, 3, 3, 3]],\n",
              " \n",
              "         [[0, 0, 0, 0],\n",
              "          [1, 1, 1, 1],\n",
              "          [2, 2, 2, 2],\n",
              "          [3, 3, 3, 3]]]), tensor([[[0, 1, 2, 3],\n",
              "          [0, 1, 2, 3],\n",
              "          [0, 1, 2, 3],\n",
              "          [0, 1, 2, 3]],\n",
              " \n",
              "         [[0, 1, 2, 3],\n",
              "          [0, 1, 2, 3],\n",
              "          [0, 1, 2, 3],\n",
              "          [0, 1, 2, 3]],\n",
              " \n",
              "         [[0, 1, 2, 3],\n",
              "          [0, 1, 2, 3],\n",
              "          [0, 1, 2, 3],\n",
              "          [0, 1, 2, 3]],\n",
              " \n",
              "         [[0, 1, 2, 3],\n",
              "          [0, 1, 2, 3],\n",
              "          [0, 1, 2, 3],\n",
              "          [0, 1, 2, 3]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_indices_chk(h=4, w=4):\n",
        "  y = torch.arange(h, dtype = torch.long)\n",
        "  x = torch.arange(w, dtype = torch.long)\n",
        "  print(y)\n",
        "  print(x)\n",
        "  y1, x1, y2, x2 = torch.meshgrid(y, x, y, x, indexing='ij')\n",
        "  return y1, x1, y2, x2 \n",
        "\n",
        "get_indices_chk()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jigd7m3lchx",
        "outputId": "189814e0-f676-4f27-dc57-657fb589553d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n",
            "tensor([0, 1, 2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1]],\n",
              " \n",
              "          [[1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1]],\n",
              " \n",
              "          [[1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1]],\n",
              " \n",
              "          [[1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1]]],\n",
              " \n",
              " \n",
              "         [[[2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2]],\n",
              " \n",
              "          [[2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2]],\n",
              " \n",
              "          [[2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2]],\n",
              " \n",
              "          [[2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2]]],\n",
              " \n",
              " \n",
              "         [[[3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3]]]]), tensor([[[[0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1]],\n",
              " \n",
              "          [[2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2]],\n",
              " \n",
              "          [[3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1]],\n",
              " \n",
              "          [[2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2]],\n",
              " \n",
              "          [[3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1]],\n",
              " \n",
              "          [[2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2]],\n",
              " \n",
              "          [[3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0],\n",
              "           [0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1],\n",
              "           [1, 1, 1, 1]],\n",
              " \n",
              "          [[2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2],\n",
              "           [2, 2, 2, 2]],\n",
              " \n",
              "          [[3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3],\n",
              "           [3, 3, 3, 3]]]]), tensor([[[[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]],\n",
              " \n",
              "          [[0, 0, 0, 0],\n",
              "           [1, 1, 1, 1],\n",
              "           [2, 2, 2, 2],\n",
              "           [3, 3, 3, 3]]]]), tensor([[[[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]]],\n",
              " \n",
              " \n",
              "         [[[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]],\n",
              " \n",
              "          [[0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3],\n",
              "           [0, 1, 2, 3]]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels, mult=4):\n",
        "        hidden_channels = in_channels * mult\n",
        "        super().__init__(\n",
        "            nn.Conv2d(in_channels, hidden_channels, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(hidden_channels, out_channels, 1)   \n",
        "        )"
      ],
      "metadata": {
        "id": "CDUwFchYlcmg"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Sequential):\n",
        "    def __init__(self, channels, head_channels, shape, p_drop=0.):\n",
        "        super().__init__(\n",
        "            Residual(\n",
        "                LayerNormChannels(channels),\n",
        "                SelfAttention2d(channels, channels, head_channels, shape),\n",
        "                nn.Dropout(p_drop)\n",
        "            ),\n",
        "            Residual(\n",
        "                LayerNormChannels(channels),\n",
        "                FeedForward(channels, channels),\n",
        "                nn.Dropout(p_drop)\n",
        "            )\n",
        "        )"
      ],
      "metadata": {
        "id": "kBJxirWVAMRV"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerStack(nn.Sequential):\n",
        "    def __init__(self, num_blocks, channels, head_channels, shape, p_drop=0.):\n",
        "        layers = [TransformerBlock(channels, head_channels, shape, p_drop) for _ in range(num_blocks)]\n",
        "        super().__init__(*layers)"
      ],
      "metadata": {
        "id": "TMA4h4yHlcpo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToPatches(nn.Sequential):\n",
        "    def __init__(self, in_channels, channels, patch_size, hidden_channels=32):\n",
        "        super().__init__(\n",
        "            nn.Conv2d(in_channels, hidden_channels, 3, padding=1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(hidden_channels, channels, patch_size, stride=patch_size)\n",
        "        )"
      ],
      "metadata": {
        "id": "tad6nm7eAkav"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddPositionEmbedding(nn.Module):\n",
        "    def __init__(self, channels, shape):\n",
        "        super().__init__()\n",
        "        self.pos_embedding = nn.Parameter(torch.Tensor(channels, *shape))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x + self.pos_embedding"
      ],
      "metadata": {
        "id": "dCU5y2TPAkdQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddClassToken(nn.Module):\n",
        "    def __init__(self, channels, shape):\n",
        "        super().__init__()\n",
        "        self.cls_token = nn.Parameter(torch.Tensor(channels,shape))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        b, _, _, _ = x.shape\n",
        "        x = self.projection(x)\n",
        "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
        "        # prepend the cls token to the input\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tZblHdstHV0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToEmbedding(nn.Sequential):\n",
        "    def __init__(self, in_channels, channels, patch_size, shape, p_drop=0.):\n",
        "        super().__init__(\n",
        "            ToPatches(in_channels, channels, patch_size),\n",
        "            AddClassToken(channels, shape),\n",
        "            AddPositionEmbedding(channels, shape),\n",
        "            nn.Dropout(p_drop)\n",
        "        )"
      ],
      "metadata": {
        "id": "mZKnZF2pAkfn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Sequential):\n",
        "    def __init__(self, in_channels, classes, p_drop=0.):\n",
        "        super().__init__(\n",
        "            LayerNormChannels(in_channels),\n",
        "            nn.GELU(),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(p_drop),\n",
        "            nn.Linear(in_channels, classes)\n",
        "        )"
      ],
      "metadata": {
        "id": "CJ0db9Z1Akkh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Sequential):\n",
        "    def __init__(self, classes, image_size, channels, head_channels, num_blocks, patch_size,\n",
        "                 in_channels=3, emb_p_drop=0., trans_p_drop=0., head_p_drop=0.):\n",
        "        reduced_size = image_size // patch_size\n",
        "        shape = (reduced_size, reduced_size)\n",
        "        super().__init__(\n",
        "            ToEmbedding(in_channels, channels, patch_size, shape, emb_p_drop),\n",
        "            TransformerStack(num_blocks, channels, head_channels, shape, trans_p_drop),\n",
        "            Head(channels, classes, head_p_drop)\n",
        "        )\n",
        "        self.reset_parameters()\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.constant_(m.weight, 1.)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, AddPositionEmbedding):\n",
        "                nn.init.normal_(m.pos_embedding, mean=0.0, std=0.02)\n",
        "            elif isinstance(m, SelfAttention2d):\n",
        "                nn.init.normal_(m.pos_enc, mean=0.0, std=0.02)\n",
        "            elif isinstance(m, Residual):\n",
        "                nn.init.zeros_(m.gamma)\n",
        "    \n",
        "    def separate_parameters(self):\n",
        "        parameters_decay = set()\n",
        "        parameters_no_decay = set()\n",
        "        modules_weight_decay = (nn.Linear, nn.Conv2d)\n",
        "        modules_no_weight_decay = (nn.LayerNorm,)\n",
        "\n",
        "        for m_name, m in self.named_modules():\n",
        "            for param_name, param in m.named_parameters():\n",
        "                full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
        "\n",
        "                if isinstance(m, modules_no_weight_decay):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif param_name.endswith(\"bias\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, Residual) and param_name.endswith(\"gamma\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, AddPositionEmbedding) and param_name.endswith(\"pos_embedding\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, SelfAttention2d) and param_name.endswith(\"pos_enc\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, modules_weight_decay):\n",
        "                    parameters_decay.add(full_param_name)\n",
        "\n",
        "        # sanity check\n",
        "        # assert len(parameters_decay & parameters_no_decay) == 0\n",
        "        # assert len(parameters_decay) + len(parameters_no_decay) == len(list(model.parameters()))\n",
        "\n",
        "        return parameters_decay, parameters_no_decay"
      ],
      "metadata": {
        "id": "6sMgEg2tAkmb"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES, IMAGE_SIZE = 10, 32\n",
        "model = ViT(NUM_CLASSES, IMAGE_SIZE, channels=32, head_channels=8, num_blocks=4, patch_size=2,\n",
        "               emb_p_drop=0., trans_p_drop=0., head_p_drop=0.1)"
      ],
      "metadata": {
        "id": "QDU5b4hfAqDt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(ViT(), (3, 224, 224), device='cpu')\n"
      ],
      "metadata": {
        "id": "mD257aiJHnSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"device:\", DEVICE)\n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDGQN5ORAqGR",
        "outputId": "f74cf80f-3fb9-4bef-93f6-5b60541579ad"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViT(\n",
              "  (0): ToEmbedding(\n",
              "    (0): ToPatches(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): GELU(approximate='none')\n",
              "      (2): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (1): AddPositionEmbedding()\n",
              "    (2): Dropout(p=0.0, inplace=False)\n",
              "  )\n",
              "  (1): TransformerStack(\n",
              "    (0): TransformerBlock(\n",
              "      (0): Residual(\n",
              "        (residual): Sequential(\n",
              "          (0): LayerNormChannels(\n",
              "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): SelfAttention2d(\n",
              "            (to_keys): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (to_queries): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (to_values): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (unifyheads): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (residual): Sequential(\n",
              "          (0): LayerNormChannels(\n",
              "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): FeedForward(\n",
              "            (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (0): Residual(\n",
              "        (residual): Sequential(\n",
              "          (0): LayerNormChannels(\n",
              "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): SelfAttention2d(\n",
              "            (to_keys): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (to_queries): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (to_values): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (unifyheads): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (residual): Sequential(\n",
              "          (0): LayerNormChannels(\n",
              "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): FeedForward(\n",
              "            (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (0): Residual(\n",
              "        (residual): Sequential(\n",
              "          (0): LayerNormChannels(\n",
              "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): SelfAttention2d(\n",
              "            (to_keys): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (to_queries): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (to_values): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (unifyheads): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (residual): Sequential(\n",
              "          (0): LayerNormChannels(\n",
              "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): FeedForward(\n",
              "            (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (0): Residual(\n",
              "        (residual): Sequential(\n",
              "          (0): LayerNormChannels(\n",
              "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): SelfAttention2d(\n",
              "            (to_keys): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (to_queries): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (to_values): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (unifyheads): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Residual(\n",
              "        (residual): Sequential(\n",
              "          (0): LayerNormChannels(\n",
              "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): FeedForward(\n",
              "            (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (2): Head(\n",
              "    (0): LayerNormChannels(\n",
              "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): GELU(approximate='none')\n",
              "    (2): AdaptiveAvgPool2d(output_size=1)\n",
              "    (3): Flatten(start_dim=1, end_dim=-1)\n",
              "    (4): Dropout(p=0.1, inplace=False)\n",
              "    (5): Linear(in_features=32, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0UVFHsuAqIu",
        "outputId": "7b59f574-4da4-43bb-c2e6-70d19f5a8ca3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 79,810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "NUM_WORKERS = 8\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 25\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-1\n",
        "\n",
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std = (0.2471, 0.2435, 0.2616)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32, scale=(0.75, 1.0), ratio=(1.0, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandAugment(num_ops=1, magnitude=8),\n",
        "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "    transforms.RandomErasing(p=0.25)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar10_mean, cifar10_std)\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "3ec5710b7bbf4703aacb8dd97d20efd6",
            "d1734a1ec9c44469b74e0385f7401776",
            "2c706e8becf5448787b34bb4116b3186",
            "755207e94faf4e4d8796a746cfca4068",
            "b696f2ac61b64805bcb5dc8ac0b4dc3b",
            "a51d2e19b7a44e9389d0b20d891a3e1f",
            "c95c51c0ca474dc0aefe5aa70254d993",
            "88dfaf8d9eb64da99157ea25b6c47d34",
            "e3cff34a21904817a2f29008949c8bc1",
            "eab40b6e339c4642960af9c483293b93",
            "a2c2a02cbcd745a591ea19417ce9bb58"
          ]
        },
        "id": "03pJaaJ3Au1T",
        "outputId": "278a8831-4947-49da-ebad-7c17cfbf52e5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ec5710b7bbf4703aacb8dd97d20efd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "clip_norm = True\n",
        "lr_schedule = lambda t: np.interp([t], [0, EPOCHS*2//5, EPOCHS*4//5, EPOCHS], \n",
        "                                  [0, 0.01, 0.01/20.0, 0])[0]\n",
        "\n",
        "model = nn.DataParallel(model, device_ids=[0]).cuda()\n",
        "opt = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc, n = 0, 0, 0\n",
        "    for i, (X, y) in enumerate(trainloader):\n",
        "        model.train()\n",
        "        X, y = X.cuda(), y.cuda()\n",
        "\n",
        "        lr = lr_schedule(epoch + (i + 1)/len(trainloader))\n",
        "        opt.param_groups[0].update(lr=lr)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(X)\n",
        "            loss = criterion(output, y)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if clip_norm:\n",
        "            scaler.unscale_(opt)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item() * y.size(0)\n",
        "        train_acc += (output.max(1)[1] == y).sum().item()\n",
        "        n += y.size(0)\n",
        "        \n",
        "    model.eval()\n",
        "    test_acc, m = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for i, (X, y) in enumerate(testloader):\n",
        "            X, y = X.cuda(), y.cuda()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = model(X)\n",
        "            test_acc += (output.max(1)[1] == y).sum().item()\n",
        "            m += y.size(0)\n",
        "\n",
        "    print(f'ConvMixer: Epoch: {epoch} | Train Acc: {train_acc/n:.4f}, Test Acc: {test_acc/m:.4f}, Time: {time.time() - start:.1f}, lr: {lr:.6f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWvseaUNAu4E",
        "outputId": "268df2f7-a2a9-4208-a279-47db0d16a5fb"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvMixer: Epoch: 0 | Train Acc: 0.2109, Test Acc: 0.3702, Time: 69.5, lr: 0.001000\n",
            "ConvMixer: Epoch: 1 | Train Acc: 0.3634, Test Acc: 0.4818, Time: 69.6, lr: 0.002000\n",
            "ConvMixer: Epoch: 2 | Train Acc: 0.4540, Test Acc: 0.5215, Time: 65.9, lr: 0.003000\n",
            "ConvMixer: Epoch: 3 | Train Acc: 0.4983, Test Acc: 0.5174, Time: 67.7, lr: 0.004000\n",
            "ConvMixer: Epoch: 4 | Train Acc: 0.5227, Test Acc: 0.5735, Time: 64.9, lr: 0.005000\n",
            "ConvMixer: Epoch: 5 | Train Acc: 0.5438, Test Acc: 0.5812, Time: 64.7, lr: 0.006000\n",
            "ConvMixer: Epoch: 6 | Train Acc: 0.5571, Test Acc: 0.6242, Time: 65.7, lr: 0.007000\n",
            "ConvMixer: Epoch: 7 | Train Acc: 0.5664, Test Acc: 0.6199, Time: 64.9, lr: 0.008000\n",
            "ConvMixer: Epoch: 8 | Train Acc: 0.5782, Test Acc: 0.6176, Time: 64.7, lr: 0.009000\n",
            "ConvMixer: Epoch: 9 | Train Acc: 0.5936, Test Acc: 0.6151, Time: 65.0, lr: 0.010000\n",
            "ConvMixer: Epoch: 10 | Train Acc: 0.6062, Test Acc: 0.6461, Time: 64.8, lr: 0.009050\n",
            "ConvMixer: Epoch: 11 | Train Acc: 0.6253, Test Acc: 0.6627, Time: 64.7, lr: 0.008100\n",
            "ConvMixer: Epoch: 12 | Train Acc: 0.6440, Test Acc: 0.6935, Time: 64.0, lr: 0.007150\n",
            "ConvMixer: Epoch: 13 | Train Acc: 0.6588, Test Acc: 0.7096, Time: 65.1, lr: 0.006200\n",
            "ConvMixer: Epoch: 14 | Train Acc: 0.6743, Test Acc: 0.7135, Time: 64.5, lr: 0.005250\n",
            "ConvMixer: Epoch: 15 | Train Acc: 0.6865, Test Acc: 0.7195, Time: 65.1, lr: 0.004300\n",
            "ConvMixer: Epoch: 16 | Train Acc: 0.7031, Test Acc: 0.7416, Time: 65.1, lr: 0.003350\n",
            "ConvMixer: Epoch: 17 | Train Acc: 0.7181, Test Acc: 0.7489, Time: 65.0, lr: 0.002400\n",
            "ConvMixer: Epoch: 18 | Train Acc: 0.7311, Test Acc: 0.7628, Time: 64.8, lr: 0.001450\n",
            "ConvMixer: Epoch: 19 | Train Acc: 0.7438, Test Acc: 0.7717, Time: 65.1, lr: 0.000500\n",
            "ConvMixer: Epoch: 20 | Train Acc: 0.7527, Test Acc: 0.7759, Time: 65.1, lr: 0.000400\n",
            "ConvMixer: Epoch: 21 | Train Acc: 0.7584, Test Acc: 0.7724, Time: 64.7, lr: 0.000300\n",
            "ConvMixer: Epoch: 22 | Train Acc: 0.7577, Test Acc: 0.7772, Time: 66.0, lr: 0.000200\n",
            "ConvMixer: Epoch: 23 | Train Acc: 0.7637, Test Acc: 0.7787, Time: 64.8, lr: 0.000100\n",
            "ConvMixer: Epoch: 24 | Train Acc: 0.7599, Test Acc: 0.7779, Time: 64.7, lr: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZHdCu77Au6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xpv9Q0njAu9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82ETKMIGAu_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "10xwRumgAvDY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}